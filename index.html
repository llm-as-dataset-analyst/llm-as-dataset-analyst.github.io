<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="LLM as Dataset Analyst">
  <meta name="keywords" content="Subpopulation Structure Discovery, Large Language Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LLM as Dataset Analyst</title>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
  <link rel="stylesheet" href="index.css">
  <link rel="icon" href="https://cdn-icons-png.flaticon.com/512/954/954591.png">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.8.0/gradio.js"></script>
</head>

<style>
  .expandable-card .card-text-container {
    max-height: 200px;
    overflow-y: hidden;
    position: relative;
  }

  .expandable-card.expanded .card-text-container {
    max-height: none;
  }

  .expand-btn {
    position: relative;
    display: none;
    background-color: rgba(255, 255, 255, 0.8);
    /* margin-top: -20px; */
    /* justify-content: center; */
    color: #510c75;
    border-color: transparent;
  }

  .expand-btn:hover {
    background-color: rgba(200, 200, 200, 0.8);
    text-decoration: none;
    border-color: transparent;
    color: #510c75;
  }

  .expand-btn:focus {
    outline: none;
    text-decoration: none;
  }

  .expandable-card:not(.expanded) .card-text-container:after {
    content: "";
    position: absolute;
    bottom: 0;
    left: 0;
    width: 100%;
    height: 90px;
    background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
  }

  .expandable-card:not(.expanded) .expand-btn {
    margin-top: -40px;
  }

  .card-body {
    padding-bottom: 5px;
  }

  .vertical-flex-layout {
    justify-content: center;
    align-items: center;
    height: 100%;
    display: flex;
    flex-direction: column;
    gap: 5px;
  }

  .figure-img {
    max-width: 100%;
    height: auto;
  }

  .adjustable-font-size {
    font-size: calc(0.5rem + 2vw);
  }

  .chat-history {
    flex-grow: 1;
    overflow-y: auto;
    /* overflow-x: hidden; */
    padding: 5px;
    border-bottom: 1px solid #ccc;
    margin-bottom: 10px;
  }

  #gradio pre {
    background-color: transparent;
  }

  .author-block a {
    color: #008AD7;
    font-weight: normal;
  }

  /* Adjust the vertical alignment and font size of the superscript */
  .author-block a sup {
    vertical-align: baseline;
    position: relative;
    top: -0.3em;
    /* Adjusts the position slightly above the baseline */
    right: -0.1em;
    /* Adjusts the position slightly to the right */
    font-size: smaller;
    /* Makes the font size smaller if needed */
  }
</style>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LLM as Dataset Analyst: Subpopulation Structure Discovery with
              Large Language Model<span class="is-size-2"><span class="is-size-1"></span></h1>
            <!--<h3 class="title is-2 publication-title">Subpopulation Structure Discovery with Large Language Model</h3>-->
            <h5 class="subtitle is-4 publication-awards">ECCV 2024</h5>
            <div class="is-size-4 publication-authors">


              <span class="author-block">
                <a href="">Yulin Luo<sup>1*</sup></a>,
              </span>


              <span class="author-block">
                <a href="">Ruichuan An<sup>2*</sup></a>,
              </span>


              <span class="author-block">
                <a href="https://www.linkedin.com/in/bocheng-zou/">Bocheng Zou<sup>3</sup></a>,
              </span>

              <span class="author-block">
                <a href="">Yiming Tang<sup>1</sup></a>,
              </span>

              <span class="author-block">
                <a href="">Jiaming Liu<sup>1</sup></a>,
              </span>


              <span class="author-block">
                <a href="https://www.shanghangzhang.com/"> Shanghang Zhang<sup>1</sup> </a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>*</sup>Equal Contribution</span>
            </div>


            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Peking University,</span>
              <span class="author-block"><sup>2</sup>Xi'an Jiaotong University,</span>
              <span class="author-block"><sup>3</sup>University of Wisconsin-Madison</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2405.02363" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/llm-as-dataset-analyst/SSDLLM" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h4 class="subtitle has-text-left">
          ðŸ”¥<span style="color: #ff3860">[NEW!]</span> Our paper <b>LLM as Dataset Analyst: Subpopulation Structure
            Discovery with Large Language Model</b> got accepted in ECCV 2024.
          <br><br>
          ðŸ”¥<span style="color: #ff3860">[NEW!]</span> We proposed the Subpopulation Structure Discovery with Large
          Language Models (SSD-LLM) framework, which employs world knowledge and instruction-following capabilities of
          Large Language Models (LLMs) to linguistically analyze informative image captions and summarize the structures
          <br><br>
        </h4>
      </div>
    </div>
  </section>

  <section class="section" style="background-color:#efeff081">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The distribution of subpopulations is an important property hidden within a dataset.
              Uncovering and analyzing the subpopulation distribution within datasets provides a comprehensive
              understanding of the datasets, standing as a powerful tool beneficial to various downstream tasks,
              including Dataset Subpopulation Organization, Subpopulation Shift, and Slice Discovery.
              Despite its importance, there has been no work that systematically explores the subpopulation distribution
              of datasets to our knowledge.
              To address the limitation and solve all the mentioned tasks in a unified way, we introduce a novel concept
              of subpopulation structures to represent, analyze, and utilize subpopulation distributions within
              datasets.
              To characterize the structures in an interpretable manner, we propose the Subpopulation Structure
              Discovery with Large Language Models (SSD-LLM) framework,
              which employs world knowledge and instruction-following capabilities of Large Language Models (LLMs) to
              linguistically analyze informative image captions and summarize the structures.
              Furthermore, we propose complete workflows to address downstream tasks, named Task-specific Tuning,
              showcasing the application of the discovered structure to a spectrum of subpopulation-related tasks,
              including dataset subpopulation organization, subpopulation shift, and slice discovery.
              With the help of SSD-LLM, we can structuralize the datasets into subpopulation-level automatically,
              achieve average +2.5 worst group accuracy gain compared to previous methods on subpopulation shift
              benchmark Waterbirds and Metashift, and also identify more consistent slice topics with a higher model
              error rate of 36.44\% on slice discovery task for ImageNet.
              The code will be available at <a
                href="https://llm-as-dataset-analyst.github.io/">https://llm-as-dataset-analyst.github.io/</a>
            </p>

          </div>
        </div>
      </div>

    </div>
  </section>

  <section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> Introduction </h2>
      </div>
    </div>
    <!-- </div> -->
    <!--/ Results. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              In our benchmark, we focus on three different types of vector graphics: SVG, TikZ, and Graphviz.
              We divide our tasks into two categories: understanding and generation.
              For understanding, we designed three different question types for each of the vector graphics based on
              their individual strength.
            </p>
          </div>
          <centering>
            <div style="text-align: center;">
              <img id="teaser" src="images/tasks.png">
            </div>
          </centering>
        </div>
  </section>


  <section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> Task Overview: Dataset Subpopulation Organization </h2>
      </div>
    </div>
    <!-- </div> -->
    <!--/ Results. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              In our benchmark, we focus on three different types of vector graphics: SVG, TikZ, and Graphviz.
              We divide our tasks into two categories: understanding and generation.
              For understanding, we designed three different question types for each of the vector graphics based on
              their individual strength.
            </p>
          </div>
          <centering>
            <div style="text-align: center;">
              <img id="teaser" src="images/tasks.png">
            </div>
          </centering>
        </div>
  </section>

  <section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> Task Overview: Subpopulation Shift </h2>
      </div>
    </div>
    <!-- </div> -->
    <!--/ Results. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              First, we obtain captions for each vector graphics image by leveraging GPT-4V over its rasterized image.
              Then we prompt the LLM to generate the vector graphics code corresponding to the caption.
              Finally, we map the generated vector graphics into rasterzied images, then use CLIP Score and FrÃ©chet
              Inception Distance (FID) Score to evaluate the quality of the generated vector graphics.
              The scores of the ground truth image is used as the upper bound to objectively evaluate the quality of the
              generated images.
            </p>
          </div>
          <centering>
            <div style="text-align: center;">
              <img id="teaser" width="70%" src="images/generation.png">
            </div>
          </centering>
        </div>
  </section>

  <section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> Task Overview: Slice Discovery </h2>
      </div>
    </div>
    <!-- </div> -->
    <!--/ Results. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              Vector graphics are converted into PNG format,
              then GPT-4V is utilized to generate the questions and
              answers (QA) candidates. Finally, human annotators
              filter the QA pairs to obtain the high-quality QA dataset.
            </p>
          </div>
          <centering>
            <div style="text-align: center;">
              <img id="teaser" width="70%" src="images/curation.png">
            </div>
          </centering>
        </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre>
        <code>
          @misc{luo2024llmdatasetanalystsubpopulation,
            title={LLM as Dataset Analyst: Subpopulation Structure Discovery with Large Language Model}, 
            author={Yulin Luo and Ruichuan An and Bocheng Zou and Yiming Tang and Jiaming Liu and Shanghang Zhang},
            year={2024},
            eprint={2405.02363},
            archivePrefix={arXiv},
            primaryClass={cs.CV},
            url={https://arxiv.org/abs/2405.02363}, 
          }
      </code>
    </pre>
    </div>
  </section>

  <section class="section" id="Acknowledgement">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgement</h2>
      <p>
        This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under
        a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>. We thank the LLaMA team for giving us access to
        their models, and open-source projects, including Alpaca and Vicuna.
      </p>

      <p>
        <b>Usage and License Notices</b>: The data, code and checkpoint is intended and licensed for research use only.
        They are also restricted to uses that follow the license agreement of CLIP, LLaMA, and GPT-4. The dataset is CC
        BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of
        research purposes.
      </p>

      <p>
        Related Links:
        <a href='https://instruction-tuning-with-gpt-4.github.io/'>[Instruction Tuning with GPT-4]</a>
      </p>
    </div>
  </section>


</body>

</html>