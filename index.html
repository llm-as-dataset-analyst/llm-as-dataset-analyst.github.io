<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="LLM as Dataset Analyst">
  <meta name="keywords" content="Subpopulation Structure Discovery, Large Language Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LLM as Dataset Analyst</title>

  <link rel="stylesheet" href="styles/pdf2htmlEX_base.min.css" />
  <link rel="stylesheet" href="styles/pdf2htmlEX_fancy.min.css" />
  <link rel="stylesheet" href="styles/intro_v5.css" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
  <link rel="stylesheet" href="index.css">
  <link rel="icon" href="https://cdn-icons-png.flaticon.com/512/954/954591.png">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.8.0/gradio.js"></script>
  <script>
    function resize_pdf(){
      const ref_element = document.querySelectorAll('.container.is-max-desktop')[0];
      const ref_style = window.getComputedStyle(ref_element);
      const target_width = ref_element.clientWidth - parseFloat(ref_style.paddingLeft) - parseFloat(ref_style.paddingRight);
      const resizing_elements = document.getElementsByClassName("auto-resize-pdf")
      for (let i = 0; i < resizing_elements.length; i++) {
          let e = resizing_elements[i];
          const origin_width = parseFloat(e.getAttribute("pdf-width"));
          const origin_height = parseFloat(e.getAttribute("pdf-height"));
          const scale = target_width / origin_width;
          e.style.transform = `scale(${scale}, ${scale})`; 
          if (scale > 1){
            e.style.transformOrigin = "center top";
          }else{
            e.style.transformOrigin = "left top";
          }
          e.style.width = origin_width*scale + "px"; 
          e.style.height = origin_height*scale + "px";
      }
    }
    window.onresize = function(event) {
      resize_pdf()
    };
    window.onload = function(event) {
      resize_pdf()
    }
  </script>
</head>

<style>
  .expandable-card .card-text-container {
    max-height: 200px;
    overflow-y: hidden;
    position: relative;
  }

  .expandable-card.expanded .card-text-container {
    max-height: none;
  }

  .expand-btn {
    position: relative;
    display: none;
    background-color: rgba(255, 255, 255, 0.8);
    /* margin-top: -20px; */
    /* justify-content: center; */
    color: #510c75;
    border-color: transparent;
  }

  .expand-btn:hover {
    background-color: rgba(200, 200, 200, 0.8);
    text-decoration: none;
    border-color: transparent;
    color: #510c75;
  }

  .expand-btn:focus {
    outline: none;
    text-decoration: none;
  }

  .expandable-card:not(.expanded) .card-text-container:after {
    content: "";
    position: absolute;
    bottom: 0;
    left: 0;
    width: 100%;
    height: 90px;
    background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
  }

  .expandable-card:not(.expanded) .expand-btn {
    margin-top: -40px;
  }

  .card-body {
    padding-bottom: 5px;
  }

  .vertical-flex-layout {
    justify-content: center;
    align-items: center;
    height: 100%;
    display: flex;
    flex-direction: column;
    gap: 5px;
  }

  .figure-img {
    max-width: 100%;
    height: auto;
  }

  .adjustable-font-size {
    font-size: calc(0.5rem + 2vw);
  }

  .chat-history {
    flex-grow: 1;
    overflow-y: auto;
    /* overflow-x: hidden; */
    padding: 5px;
    border-bottom: 1px solid #ccc;
    margin-bottom: 10px;
  }

  #gradio pre {
    background-color: transparent;
  }

  .author-block a {
    color: #008AD7;
    font-weight: normal;
  }

  /* Adjust the vertical alignment and font size of the superscript */
  .author-block a sup {
    vertical-align: baseline;
    position: relative;
    top: -0.3em;
    /* Adjusts the position slightly above the baseline */
    right: -0.1em;
    /* Adjusts the position slightly to the right */
    font-size: smaller;
    /* Makes the font size smaller if needed */
  }
</style>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LLM as Dataset Analyst: Subpopulation Structure Discovery with
              Large Language Model<span class="is-size-2"><span class="is-size-1"></span></h1>
            <!--<h3 class="title is-2 publication-title">Subpopulation Structure Discovery with Large Language Model</h3>-->
            <h5 class="subtitle is-4 publication-awards">ECCV 2024</h5>
            <div class="is-size-4 publication-authors">


              <span class="author-block">
                <a href="">Yulin Luo<sup>1*</sup></a>,
              </span>


              <span class="author-block">
                <a href="">Ruichuan An<sup>1,2*</sup></a>,
              </span>


              <span class="author-block">
                <a href="https://www.linkedin.com/in/bocheng-zou/">Bocheng Zou<sup>1,3</sup></a>,
              </span>

              <span class="author-block">
                <a href="">Yiming Tang<sup>1,4</sup></a>,
              </span>

              <span class="author-block">
                <a href="">Jiaming Liu<sup>1</sup></a>,
              </span>


              <span class="author-block">
                <a href="https://www.shanghangzhang.com/"> Shanghang Zhang<sup>1#</sup> </a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>*</sup>Equal Contribution</span>
              <span class="author-block"><sup>#</sup>Corresponding Author</span>
            </div>


            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Peking University,</span>
              <span class="author-block"><sup>2</sup>Xi'an Jiaotong University,</span>
              <span class="author-block"><sup>3</sup>University of Wisconsin-Madison,</span>
              <span class="author-block"><sup>4</sup>National University of Singapore</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2405.02363" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/llm-as-dataset-analyst/SSDLLM" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h4 class="subtitle has-text-left">
          ðŸ”¥<span style="color: #ff3860">[NEW!]</span> Our paper <b>LLM as Dataset Analyst: Subpopulation Structure
            Discovery with Large Language Model</b> got accepted in ECCV 2024.
          <br><br>
          ðŸ”¥<span style="color: #ff3860">[NEW!]</span> We proposed the Subpopulation Structure Discovery with Large
          Language Models (SSD-LLM) framework, which employs world knowledge and instruction-following capabilities of
          Large Language Models (LLMs) to linguistically analyze informative image captions and summarize the structures
          <br><br>
        </h4>
      </div>
    </div>
  </section>

  <section class="section" style="background-color:#efeff081">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              <p>
                The distribution of subpopulations is an important property hidden within a dataset.
                Uncovering and analyzing the subpopulation distribution within datasets provides a comprehensive
                understanding of the datasets, standing as a powerful tool beneficial to various downstream tasks,
                including Dataset Subpopulation Organization, Subpopulation Shift, and Slice Discovery.
                Despite its importance, there has been no work that systematically explores the subpopulation distribution
                of datasets to our knowledge.
              </p>
              <p>
                To address the limitation and solve all the mentioned tasks in a unified way, we introduce a novel concept
                of subpopulation structures to represent, analyze, and utilize subpopulation distributions within
                datasets.
                To characterize the structures in an interpretable manner, we propose the Subpopulation Structure
                Discovery with Large Language Models (SSD-LLM) framework,
                which employs world knowledge and instruction-following capabilities of Large Language Models (LLMs) to
                linguistically analyze informative image captions and summarize the structures.
                Furthermore, we propose complete workflows to address downstream tasks, named Task-specific Tuning,
                showcasing the application of the discovered structure to a spectrum of subpopulation-related tasks,
                including dataset subpopulation organization, subpopulation shift, and slice discovery.
              </p>
              <p>
                With the help of SSD-LLM, we can structuralize the datasets into subpopulation-level automatically, 
                achieve average +3.3% worst group accuracy gain compared to previous methods on subpopulation 
                shift benchmark Waterbirds, Metashift and Nico++, and also identify more consistent slice topics 
                with a higher model error rate of 3.95% on slice discovery task for ImageNet.
              </p>
            </p>

          </div>
        </div>
      </div>

    </div>
  </section>

  <section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> Introduction </h2>
      </div>
    </div>
    <!-- </div> -->
    <!--/ Results. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              We proposed a novel framework <b>Subpopulation Structure Discovery with Large Language Model (SSD-LLM)</b> 
              to automatically uncover the structure. The core idea is to generate informative captions from images with MLLM, 
              followed by analyzing and summarizing the subpopulation structure of datasets with LLM.
            </p>
          </div>
        </div>
      </div>
      <div class="auto-resize-pdf" pdf-width="708.6" pdf-height="402.48">
        <div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><img class="bi x0 y0 w1 p_h1" alt="" src="images/bg1.png"/><div class="c x0 y1 w2 h0"><div class="t m0 x1 p_h2 y2 ff1 fs0 fc0 sc0 ls0 ws0">Dimension</div><div class="t m0 x2 p_h2 y3 ff1 fs0 fc0 sc0 ls0 ws0">Class</div><div class="t m0 x3 p_h2 y4 ff1 fs0 fc0 sc0 ls0 ws0">Attribute</div><div class="t m0 x4 p_h3 y5 ff1 fs1 fc0 sc0 ls0 ws0">action</div><div class="t m0 x5 p_h4 y6 ff1 fs2 fc0 sc0 ls1 ws0">dog</div><div class="t m0 x6 p_h3 y7 ff1 fs1 fc0 sc0 ls0 ws0">background<span class="_ _0"> </span>object</div><div class="t m0 x7 p_h5 y8 ff2 fs3 fc0 sc0 ls0 ws0">Subpopu<span class="_ _1"></span>lation St<span class="_ _1"></span>ructure</div><div class="t m0 x8 p_h3 y9 ff1 fs1 fc0 sc0 ls0 ws0">surf</div><div class="t m0 x9 p_h3 ya ff1 fs1 fc0 sc0 ls0 ws0">sit<span class="_ _2"> </span>walk<span class="_ _3"> </span>water</div><div class="t m0 xa p_h3 yb ff1 fs1 fc0 sc0 ls0 ws0">snow</div><div class="t m0 xb p_h3 ya ff1 fs1 fc0 sc0 ls0 ws0">grass</div><div class="t m0 xc p_h3 yc ff1 fs1 fc0 sc0 ls0 ws0">beach</div><div class="t m0 xd p_h3 ya ff1 fs1 fc0 sc0 ls0 ws0">frisbee</div><div class="t m0 xe p_h3 yc ff1 fs1 fc0 sc0 ls0 ws0">house</div><div class="t m0 xf p_h6 yd ff2 fs0 fc0 sc0 ls0 ws0">Subpopulations</div><div class="t m0 x10 p_h7 ye ff3 fs4 fc0 sc1 ls2 ws0">SSD<span class="ls0">-<span class="_ _4"></span>LL<span class="_ _4"></span>M</span></div><div class="t m0 x11 p_h8 yf ff3 fs5 fc0 sc1 ls0 ws0">Down<span class="_ _4"></span>str<span class="_ _4"></span>ea<span class="_ _4"></span>m </div><div class="t m0 x12 p_h8 y10 ff3 fs5 fc0 sc1 ls0 ws0">Task<span class="_ _4"></span>s</div><div class="t m0 x13 p_h9 y11 ff2 fs6 fc0 sc0 ls0 ws0">(A) SSD with <span class="_ _4"></span>LLM</div><div class="t m0 x14 ha y12 ff2 fs7 fc0 sc0 ls0 ws0">Dataset</div><div class="t m0 x3 hb y13 ff2 fs2 fc0 sc0 ls0 ws0">Criteria</div><div class="t m0 x15 hc y14 ff2 fs8 fc0 sc0 ls0 ws0">(C) Subpopulation Shift</div><div class="t m0 x16 p_h2 y15 ff1 fs0 fc0 sc0 ls0 ws0">Better L<span class="_ _4"></span>ong-tail <span class="_ _5"></span>Performance</div><div class="t m0 x17 p_h2 y16 ff1 fs0 fc0 sc0 ls0 ws0">Density</div><div class="t m0 xf p_h2 y17 ff1 fs0 fc0 sc0 ls3 ws0">SSD<span class="ls0">-L<span class="_ _4"></span>L<span class="_ _4"></span>M <span class="_ _1"></span> +</span></div><div class="t m0 xf p_h2 y18 ff1 fs0 fc0 sc0 ls0 ws0">Imag<span class="_ _4"></span>e Generation</div><div class="t m1 x18 p_h2 y19 ff1 fs0 fc0 sc0 ls0 ws0">Accuracy</div><div class="t m0 x19 p_h4 y1a ff1 fs2 fc0 sc0 ls0 ws0">sit</div><div class="t m0 x1a p_h4 y1b ff1 fs2 fc0 sc0 ls0 ws0">house</div><div class="t m0 x1b p_h4 y1c ff1 fs2 fc0 sc0 ls0 ws0">surf</div><div class="t m0 x1c hd y1d ff4 fs2 fc0 sc0 ls0 ws0">â€¦</div><div class="t m0 x1d p_h3 y1e ff1 fs1 fc0 sc0 ls0 ws0">Model</div><div class="t m0 x1e p_h3 y1f ff1 fs1 fc0 sc0 ls0 ws0">Model*</div><div class="t m0 x1f p_h4 y20 ff1 fs2 fc0 sc0 ls0 ws0">sit<span class="_ _6"> </span>walk</div><div class="t m0 x20 p_h4 y21 ff1 fs2 fc0 sc0 ls0 ws0">surf</div><div class="t m0 x21 hd y22 ff4 fs2 fc0 sc0 ls0 ws0">â€¦</div><div class="t m0 x22 p_h2 y23 ff1 fs0 fc0 sc0 ls0 ws0">Density</div><div class="t m0 x23 hc y24 ff2 fs8 fc0 sc0 ls0 ws0">(B) Dataset <span class="_ _1"></span>Subpopulation Organization</div><div class="t m0 x24 p_h4 y25 ff1 fs2 fc0 sc0 ls0 ws0">Organized Subpop<span class="_ _1"></span>ulations</div><div class="t m0 x25 p_h2 y26 ff1 fs0 fc0 sc0 ls0 ws0">Dimensions</div><div class="t m0 x26 p_h2 y27 ff1 fs0 fc0 sc0 ls0 ws0">Class</div><div class="t m0 x27 p_h2 y28 ff1 fs0 fc0 sc0 ls0 ws0">Attribute<span class="_ _4"></span>s</div><div class="t m0 x27 hb y29 ff2 fs2 fc0 sc0 ls0 ws0">Criteria</div><div class="t m1 x28 he y2a ff1 fs9 fc0 sc0 ls0 ws0">Dim<span class="_ _4"></span>ension:</div><div class="t m1 x29 he y2a ff1 fs9 fc0 sc0 ls0 ws0">Action</div><div class="t m1 x2a he y2b ff1 fs9 fc0 sc0 ls0 ws0">Dim<span class="_ _4"></span>ension:</div><div class="t m1 x2b he y2b ff1 fs9 fc0 sc0 ls0 ws0">Backgrou<span class="_ _4"></span>nd</div><div class="t m0 x2c he y2c ff1 fs9 fc0 sc0 ls0 ws0">Surf</div><div class="t m0 x2d he y2d ff1 fs9 fc0 sc0 ls0 ws0">Sit</div><div class="t m0 x2e he y2e ff1 fs9 fc0 sc0 ls0 ws0">Walk</div><div class="t m0 x2f he y2f ff1 fs9 fc0 sc0 ls0 ws0">Water</div><div class="t m0 x30 hf y30 ff1 fsa fc0 sc0 ls0 ws0">Snow<span class="_ _7"> </span>Grass</div><div class="t m1 x2a he y31 ff1 fs9 fc0 sc0 ls0 ws0">Dim<span class="_ _4"></span>ension:</div><div class="t m1 x2b he y31 ff1 fs9 fc0 sc0 ls0 ws0">Object</div><div class="t m0 x2c he y32 ff1 fs9 fc0 sc0 ls0 ws0">Beach</div><div class="t m0 x30 he y33 ff1 fs9 fc0 sc0 ls0 ws0">Fri<span class="_ _4"></span>sbee<span class="_ _8"> </span>House</div><div class="t m0 x31 hc y34 ff2 fs8 fc0 sc0 ls0 ws0">(D) Slice Disco<span class="_ _1"></span>very </div><div class="t m0 x32 p_h2 y35 ff1 fs0 fc0 sc0 ls0 ws0">Topic <span class="_ _4"></span>Generat<span class="_ _4"></span>ion</div><div class="t m0 x32 p_h2 y36 ff1 fs0 fc0 sc0 ls0 ws0">+<span class="_"> </span>Imag<span class="_ _4"></span>e<span class="_"> </span>Retrieval</div><div class="t m0 x33 hb y37 ff2 fs2 fc0 sc0 ls0 ws0">Class<span class="_ _9"> </span>Dim<span class="_ _4"></span>ension<span class="_ _a"> </span>Attribute<span class="_ _b"> </span>Error Rate</div><div class="t m0 x34 h10 y38 ff1 fsb fc0 sc0 ls0 ws0">Dog</div><div class="t m0 x35 p_h4 y39 ff1 fs2 fc0 sc0 ls0 ws0">Action</div><div class="t m0 x36 p_h4 y3a ff1 fs2 fc0 sc0 ls0 ws0">Ly<span class="_ _4"></span>ing<span class="_ _c"> </span><span class="fc1 ls1">25%</span></div><div class="t m0 x37 p_h4 y3b ff1 fs2 fc0 sc0 ls0 ws0">Walking<span class="_ _d"> </span><span class="ls1">8%</span></div><div class="t m0 xd h10 y38 ff1 fsb fc0 sc0 ls0 ws0">Backg<span class="_ _4"></span>round</div><div class="t m0 x36 p_h4 y3c ff1 fs2 fc0 sc0 ls0 ws0">Beach<span class="_ _e"> </span><span class="ls1">9%</span></div><div class="t m0 x36 p_h4 y3d ff1 fs2 fc0 sc0 ls0 ws0">House<span class="_ _f"> </span><span class="ls1">6%</span></div><div class="t m0 x35 p_h4 y3e ff1 fs2 fc0 sc0 ls0 ws0">Object</div><div class="t m0 x38 p_h4 y3f ff1 fs2 fc0 sc0 ls0 ws0">Bed<span class="_ _10"> </span><span class="fc1 ls1">19%</span></div><div class="t m0 x39 p_h4 y40 ff1 fs2 fc0 sc0 ls0 ws0">Boat<span class="_ _11"> </span><span class="fc1 ls1">27%</span></div><div class="t m0 x3a p_h2 y41 ff1 fs0 fc0 sc0 ls0 ws0">Val<span class="_ _4"></span>idatio<span class="_ _4"></span>n accurac<span class="_ _4"></span>y for di<span class="_ _4"></span>fferent <span class="_ _4"></span>attribute<span class="_ _4"></span>s</div><div class="t m0 x3b h11 y42 ff1 fsc fc0 sc0 ls0 ws0">A dog standing on a <span class="fc1">boat</span>.</div><div class="t m0 x3b h11 y43 ff1 fsc fc0 sc0 ls0 ws0">Error R<span class="_ _1"></span>ate: 19%</div><div class="t m0 x3c h11 y44 ff1 fsc fc0 sc0 ls0 ws0">A dog <span class="fc1">ly<span class="_ _4"></span>ing<span class="_ _12"> </span><span class="fc0">in a </span>bed<span class="fc0">.</span></span></div><div class="t m0 x3c h11 y45 ff1 fsc fc0 sc0 ls0 ws0">Error R<span class="_ _1"></span>ate: 20%</div><div class="t m0 x34 h12 y46 ff2 fsd fc0 sc0 ls0 ws0">Slices</div><div class="t m0 x1f p_h4 y47 ff1 fs2 fc0 sc0 ls0 ws0">sit</div><div class="t m0 x3d p_h4 y48 ff1 fs2 fc0 sc0 ls0 ws0">walk</div><div class="t m0 x20 p_h4 y49 ff1 fs2 fc0 sc0 ls0 ws0">surf</div><div class="t m0 x21 hd y4a ff4 fs2 fc0 sc0 ls0 ws0">â€¦</div><div class="t m0 x3e p_h4 y4b ff1 fs2 fc0 sc0 ls0 ws0">Action</div><div class="t m0 x3e p_h4 y4c ff1 fs2 fc0 sc0 ls0 ws0">Action</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
      </div>
    </div>
  </section>


  <section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> Task Overview: Dataset Subpopulation Organization </h2>
      </div>
    </div>
    <!-- </div> -->
    <!--/ Results. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              In our benchmark, we focus on three different types of vector graphics: SVG, TikZ, and Graphviz.
              We divide our tasks into two categories: understanding and generation.
              For understanding, we designed three different question types for each of the vector graphics based on
              their individual strength.
            </p>
          </div>
          <centering>
            <div style="text-align: center;">
              <img id="teaser" src="images/tasks.png">
            </div>
          </centering>
        </div>
  </section>

  <section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> Task Overview: Subpopulation Shift </h2>
      </div>
    </div>
    <!-- </div> -->
    <!--/ Results. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              First, we obtain captions for each vector graphics image by leveraging GPT-4V over its rasterized image.
              Then we prompt the LLM to generate the vector graphics code corresponding to the caption.
              Finally, we map the generated vector graphics into rasterzied images, then use CLIP Score and FrÃ©chet
              Inception Distance (FID) Score to evaluate the quality of the generated vector graphics.
              The scores of the ground truth image is used as the upper bound to objectively evaluate the quality of the
              generated images.
            </p>
          </div>
          <centering>
            <div style="text-align: center;">
              <img id="teaser" width="70%" src="images/generation.png">
            </div>
          </centering>
        </div>
  </section>

  <section class="section">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3"> Task Overview: Slice Discovery </h2>
      </div>
    </div>
    <!-- </div> -->
    <!--/ Results. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <p>
              Vector graphics are converted into PNG format,
              then GPT-4V is utilized to generate the questions and
              answers (QA) candidates. Finally, human annotators
              filter the QA pairs to obtain the high-quality QA dataset.
            </p>
          </div>
          <centering>
            <div style="text-align: center;">
              <img id="teaser" width="70%" src="images/curation.png">
            </div>
          </centering>
        </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre>
        <code>
          @misc{luo2024llmdatasetanalystsubpopulation,
            title={LLM as Dataset Analyst: Subpopulation Structure Discovery with Large Language Model}, 
            author={Yulin Luo and Ruichuan An and Bocheng Zou and Yiming Tang and Jiaming Liu and Shanghang Zhang},
            year={2024},
            eprint={2405.02363},
            archivePrefix={arXiv},
            primaryClass={cs.CV},
            url={https://arxiv.org/abs/2405.02363}, 
          }
      </code>
    </pre>
    </div>
  </section>

  <section class="section" id="Acknowledgement">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgement</h2>
      <p>
        This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under
        a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>. We thank the LLaMA team for giving us access to
        their models, and open-source projects, including Alpaca and Vicuna.
      </p>

      <p>
        <b>Usage and License Notices</b>: The data, code and checkpoint is intended and licensed for research use only.
        They are also restricted to uses that follow the license agreement of CLIP, LLaMA, and GPT-4. The dataset is CC
        BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of
        research purposes.
      </p>

      <p>
        Related Links:
        <a href='https://instruction-tuning-with-gpt-4.github.io/'>[Instruction Tuning with GPT-4]</a>
      </p>
    </div>
  </section>


</body>

</html>